{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## neutral sentiment graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1_network_df\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "pd.set_option('display.mpl_style', 'default') \n",
    "pd.set_option('display.width', 5000) \n",
    "pd.set_option('display.max_columns', 60)\n",
    "\n",
    "gml_files = glob('../output/network/article_neu1.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_graph_inf(graph):\n",
    "    graph.name = filename\n",
    "    info = nx.info(graph)\n",
    "    print info\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    #nx.draw_spring(graph, arrows=True, with_labels=True)\n",
    "\n",
    "def highest_centrality(cent_dict):\n",
    "    \"\"\"Returns a tuple (node,value) with the node\n",
    "    with largest value from centrality dictionary.\"\"\"\n",
    "    # create ordered tuple of centrality data\n",
    "    cent_items = [(b,a) for (a,b) in cent_dict.iteritems()]\n",
    "    # sort in descending order\n",
    "    cent_items.sort()\n",
    "    cent_items.reverse()\n",
    "    return tuple(reversed(cent_items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network_data_columns = ['name',\n",
    "                    'sentiment',\n",
    "                    'n nodes',\n",
    "                    'n edges',\n",
    "                    'avg degree',\n",
    "                    'density',\n",
    "                    'avg deg cent',\n",
    "                    'avg bet cent',\n",
    "                    'avg clo cent',\n",
    "                    'highest degc',\n",
    "                    'highest betc',\n",
    "                    'highest cloc',\n",
    "                    'avg node connect',\n",
    "                    'deg assort coeff',\n",
    "                    'avg in-deg',\n",
    "                    'avg out-deg',\n",
    "                    'n strong comp',\n",
    "                    'n weak comp',\n",
    "                    'n conn comp',\n",
    "                    'Gc size'\n",
    "                    ]\n",
    "network_data = pd.DataFrame(columns = network_data_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# graph = directed, ugraph = undirected\n",
    "for graph_num, gml_graph in enumerate(gml_files):\n",
    "    graph = nx.read_gml(gml_graph)\n",
    "    ugraph = graph.to_undirected() # to undirected graph\n",
    "    U = graph.to_undirected(reciprocal=True)\n",
    "    e = U.edges()\n",
    "    ugraph.add_edges_from(e)\n",
    "    (filepath, filename) = os.path.split(gml_graph)\n",
    "    print('-' * 10)\n",
    "    print(gml_graph)\n",
    "    calculate_graph_inf(graph)\n",
    "    calculate_graph_inf(ugraph)\n",
    "    \n",
    "    # calculate variables\n",
    "    #sent = filepath.split('/')[-1]\n",
    "    sent = neutral\n",
    "    nodes = nx.number_of_nodes(graph)\n",
    "    edges = nx.number_of_edges(graph)\n",
    "    density = float(\"{0:.4f}\".format(nx.density(graph)))\n",
    "    avg_deg_cen = np.array(nx.degree_centrality(graph).values()).mean()\n",
    "    avg_bet_cen = np.array(nx.betweenness_centrality(graph).values()).mean()\n",
    "    avg_clo_cen = np.array(nx.closeness_centrality(graph).values()).mean()\n",
    "    in_deg = sum(graph.in_degree().values())/float(nx.number_of_nodes(graph))\n",
    "    out_deg = sum(graph.out_degree().values())/float(nx.number_of_nodes(graph))\n",
    "    avg_deg = float(\"{0:.4f}\".format(in_deg + out_deg))\n",
    "    strong_comp = nx.number_strongly_connected_components(graph)\n",
    "    weak_comp =  nx.number_weakly_connected_components(graph)\n",
    "    avg_node_con = float(\"{0:.4f}\".format((nx.average_node_connectivity(graph))))\n",
    "    deg_assort_coeff = float(\"{0:.4f}\".format((nx.degree_assortativity_coefficient(graph))))\n",
    "    conn_comp = nx.number_connected_components(ugraph)\n",
    "    deg_cen = nx.degree_centrality(graph)\n",
    "    bet_cen = nx.betweenness_centrality(graph)\n",
    "    clo_cen = nx.closeness_centrality(graph)\n",
    "    highest_deg_cen = highest_centrality(deg_cen)\n",
    "    highest_bet_cen = highest_centrality(bet_cen)\n",
    "    highest_clo_cen = highest_centrality(clo_cen)\n",
    "    Gc = len(max(nx.connected_component_subgraphs(ugraph), key=len))\n",
    "\n",
    "    # save variables into list\n",
    "    graph_values = {'name':filename,\n",
    "                    'sentiment':sent,\n",
    "                    'n nodes':nodes,\n",
    "                    'n edges':edges,\n",
    "                    'avg degree':avg_deg,\n",
    "                    'density':density,\n",
    "                    'avg deg cent':\"%.4f\" % avg_deg_cen,\n",
    "                    'avg bet cent':\"%.4f\" % avg_bet_cen,\n",
    "                    'avg clo cent':\"%.4f\" % avg_clo_cen,\n",
    "                    'highest degc':highest_deg_cen,\n",
    "                    'highest betc':highest_bet_cen,\n",
    "                    'highest cloc':highest_clo_cen,\n",
    "                    'avg node connect':avg_node_con,\n",
    "                    'deg assort coeff':deg_assort_coeff,\n",
    "                    'avg in-deg':\"%.4f\" % in_deg,\n",
    "                    'avg out-deg':\"%.4f\" % out_deg,\n",
    "                    'n strong comp':strong_comp,\n",
    "                    'n weak comp':weak_comp,\n",
    "                    'n conn comp':conn_comp,\n",
    "                    'Gc size':Gc\n",
    "                    }\n",
    "    \n",
    "    network_data = network_data.append(graph_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network_data\n",
    "\n",
    "# save to csv\n",
    "#network_data.to_csv('output/network_df_neg.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2_node_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create empty dataframe with columns\n",
    "data_columns = ['name',\n",
    "                'sentiment'\n",
    "                ]\n",
    "data = pd.DataFrame(columns = data_columns)\n",
    "combined_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# graph = directed, ugraph = undirected\n",
    "for graph_num, gml_graph in enumerate(gml_files):\n",
    "    print('-' * 40)\n",
    "    print(gml_graph)\n",
    "    calculate_graph_inf(graph)\n",
    "    calculate_graph_inf(ugraph)\n",
    "\n",
    "    # calculate variables and save into list\n",
    "    sent = filepath.split('/')[-1]\n",
    "    deg_cent = nx.degree_centrality(graph)\n",
    "    bet_cent = nx.betweenness_centrality(graph)\n",
    "    clo_cent = nx.closeness_centrality(graph)\n",
    "    graph_values = {'name':filename,\n",
    "                    'sentiment':sent,\n",
    "                    }\n",
    "    data = data.append(graph_values, ignore_index=True)\n",
    "\n",
    "    degree = nx.degree(graph)\n",
    "    deg_df = pd.DataFrame.from_dict(degree, orient = 'index')\n",
    "    deg_df.columns = ['degree']\n",
    "    # degree centrality\n",
    "    deg_cent = nx.degree_centrality(graph)\n",
    "    dc_df = pd.DataFrame.from_dict(deg_cent, orient = 'index')\n",
    "    dc_df.columns = ['degree centrality']\n",
    "    # betweenness centrality\n",
    "    bet_cent = nx.betweenness_centrality(graph)\n",
    "    bc_df = pd.DataFrame.from_dict(bet_cent, orient = 'index')\n",
    "    bc_df.columns = ['betweenness centrality']\n",
    "    # closeness centrality\n",
    "    clo_cent = nx.closeness_centrality(graph)\n",
    "    cc_df = pd.DataFrame.from_dict(clo_cent, orient = 'index')\n",
    "    cc_df.columns = ['closeness centrality']\n",
    "    \n",
    "    # concat node frames into node_df\n",
    "    frames = [deg_df, dc_df, bc_df, cc_df]\n",
    "    node_df = pd.concat(frames, axis = 1)\n",
    "    node_df.index.name = 'node'\n",
    "    node_df = node_df.reset_index()\n",
    "    \n",
    "    values = pd.DataFrame(graph_values, columns = ('name', 'sentiment'), index = [0])\n",
    "    \n",
    "    # df = merges graph_values with node_df for single graph and fill NaNs\n",
    "    df = pd.concat([values, node_df], axis = 1)\n",
    "    df = df.fillna(method='ffill')\n",
    "    combined_df = combined_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df\n",
    "\n",
    "# save dataframe to csv\n",
    "#combined_df.to_csv('1_df.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 7_negative_graph_calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawIt(graph, what = 'graph'):\n",
    "    nsize = graph.number_of_nodes()\n",
    "    print \"Drawing %s of size %s:\" % (what, nsize)\n",
    "    \n",
    "    if nsize > 20:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        if nsize > 40:\n",
    "            nx.draw_spring(graph, with_labels = True, node_size = 70, font_size = 12)\n",
    "        else:\n",
    "            nx.draw_spring(graph, with_labels = True)\n",
    "    else:\n",
    "        nx.draw_spring(graph, with_labels = True)\n",
    "    plt.show()\n",
    "\n",
    "def describeGraph(graph):\n",
    "    components = sorted(nx.connected_components(graph), key = len, reverse = True)\n",
    "    cc = [len(c) for c in components]\n",
    "    subgraphs = list(nx.connected_component_subgraphs(graph))\n",
    "    params = (graph.number_of_edges(),graph.number_of_nodes(),len(cc))\n",
    "    print \"Graph has %s nodes, %s edges, %s connected components\\n\" % params\n",
    "    drawIt(graph)\n",
    "    for sub in components:\n",
    "        drawIt(graph.subgraph(sub), what = 'component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# components and connectivity\n",
    "\n",
    "# list of connected components (sets of nodes), starting with largest\n",
    "print \"List of connected components =\", [len(c) for c in sorted(nx.connected_components(ugraph), key=len, reverse=True)]\n",
    "\n",
    "# generate connected components as subgraphs; Gc is largest component\n",
    "subgraphs = list(nx.connected_component_subgraphs(ugraph))\n",
    "\n",
    "# greatest component\n",
    "Gc = max(nx.connected_component_subgraphs(ugraph), key=len)\n",
    "print \"Size of greatest component =\", len(Gc)\n",
    "\n",
    "# returns all minimum k cutsets of an undirected graph\n",
    "# i.e., the set(s) of nodes of cardinality equal to the node connectivity of G\n",
    "# thus if removed, would break G into two or more connected components\n",
    "cutsets = list(nx.all_node_cuts(Gc))\n",
    "print \"# of cutsets =\", len(cutsets)\n",
    "\n",
    "# returns a set of nodes or edges of minimum cardinality that disconnects G\n",
    "print \"Min node cut =\", nx.minimum_node_cut(Gc, s='vaccines', t='autism')\n",
    "print \"Min edge cut =\", nx.minimum_edge_cut(Gc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############ fix below\n",
    "\n",
    "nx.minimum_node_cut(Gc, s='vaccines', t='autism')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "a = nx.minimum_edge_cut(Gc, s='autism', t='vaccines')\n",
    "a\n",
    "\n",
    "##\n",
    "labels = nx.get_edge_attributes(Gc,'edge')\n",
    "edgelabels = {}\n",
    "for e in labels.keys():\n",
    "    e1 = e[0:2]\n",
    "    edgelabels[e1]=labels[e]\n",
    "edgelabels\n",
    "\n",
    "##\n",
    "for e in a:\n",
    "    if edgelabels.has_key(e):\n",
    "        print e,edgelabels[e]\n",
    "    else:\n",
    "        rev_e = e[::-1]\n",
    "        print rev_e, edgelabels[rev_e]\n",
    "\n",
    "# this takes forever\n",
    "# average connectivity k of a graph G is the average of local node connectivity over all pairs of nodes of G\n",
    "#nx.average_node_connectivity(Gc)\n",
    "\n",
    "# NEW SUMMARY\n",
    "print \"List of connected components =\", [len(c) for c in sorted(nx.connected_components(ugraph), key=len, reverse=True)]\n",
    "print \"Size of greatest component =\", len(Gc)\n",
    "print \"# of cutsets =\", len(cutsets)\n",
    "print \"Min node cut =\", nx.minimum_node_cut(Gc)\n",
    "print \"Min edge cut =\", nx.minimum_edge_cut(Gc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8_single_calc_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#describeGraph(ugraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# degree histogram: returns a list of frequencies of degrees\n",
    "print nx.degree_histogram(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# degree rank plot (undirected)\n",
    "degree_sequence=sorted(nx.degree(ugraph).values(),reverse=True) # degree sequence\n",
    "#print \"Degree sequence\", degree_sequence\n",
    "dmax=max(degree_sequence)\n",
    "\n",
    "plt.loglog(degree_sequence,'b-',marker='o')\n",
    "plt.title(\"Degree rank plot\")\n",
    "plt.ylabel(\"degree\")\n",
    "plt.xlabel(\"rank\")\n",
    "\n",
    "# draw graph in inset\n",
    "plt.axes([0.45,0.45,0.45,0.45])\n",
    "Gcc=sorted(nx.connected_component_subgraphs(ugraph), key = len, reverse=True)[0]\n",
    "pos=nx.spring_layout(Gcc)\n",
    "plt.axis('off')\n",
    "nx.draw_networkx_nodes(Gcc,pos,node_size=20)\n",
    "nx.draw_networkx_edges(Gcc,pos,alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# degree centrality\n",
    "a = nx.degree_centrality(graph)\n",
    "dfIn=pd.DataFrame.from_dict(a,orient='index')\n",
    "dfIn.columns = ['degree centrality']\n",
    "dfIn = dfIn.sort_values(by=['degree centrality'])\n",
    "dfIn\n",
    "\n",
    "# betweenness centrality\n",
    "a = nx.betweenness_centrality(graph)\n",
    "dfIn=pd.DataFrame.from_dict(a,orient='index')\n",
    "dfIn.columns = ['betweenness centrality']\n",
    "dfIn = dfIn.sort_values(by=['betweenness centrality'])\n",
    "dfIn\n",
    "\n",
    "# closeness centrality\n",
    "a = nx.closeness_centrality(graph)\n",
    "dfIn=pd.DataFrame.from_dict(a,orient='index')\n",
    "dfIn.columns = ['closeness centrality']\n",
    "dfIn = dfIn.sort_values(by=['closeness centrality'])\n",
    "dfIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
